version: "3"
services:
  # https://raw.githubusercontent.com/bitnami/containers/main/bitnami/spark/docker-compose.yml
  spark:
    image: bitnami/spark:3.3-debian-11
    container_name: spark
    environment:
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - KAFKA_HOST=kafka:29092
      - PYSPARK_SUBMIT_ARGS=--packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1 pyspark-shell
    ports:
      - '8080:8080'
      - '7077:7077'
      - '41573:41573'
  spark-worker:
    # image: docker.io/bitnami/spark:3.3
    # build: Dockerfile.spark
    container_name: spark-worker
    build:
      dockerfile: Dockerfile.spark
    ports:
      - '8091:8081'
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark:7077
      - SPARK_WORKER_MEMORY=16G
      - SPARK_WORKER_CORES=4
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - KAFKA_HOST=kafka:29092
      - PYSPARK_SUBMIT_ARGS=--packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1 pyspark-shell
    depends_on:
      - spark

  # https://github.com/bitnami/containers/blob/main/bitnami/kafka/docker-compose.yml
  zookeeper:
    image: docker.io/bitnami/zookeeper:3.8
    ports:
      - "2181:2181"
    # volumes:
    #   - "zookeeper_data:/bitnami"
    environment:
      - ALLOW_ANONYMOUS_LOGIN=yes

  kafka:
    image: docker.io/bitnami/kafka:3.3
    container_name: kafka
    ports:
      - "9092:9092"
    # volumes:
    #   - "kafka_data:/bitnami"
    environment:
      - KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      - KAFKA_LISTENERS=PLAINTEXT://kafka:29092,CONTROLLER://kafka:29093,PLAINTEXT_HOST://0.0.0.0:9092
    depends_on:
      - zookeeper

  kafka-ui:
    container_name: kafka-ui
    image: provectuslabs/kafka-ui:latest
    ports:
      - 8081:8080
    depends_on:
      - kafka
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:29092

  # cassandra:
  #   container_name: cassandra
  #   image: cassandra:4.1.0
  #   ports:
  #     - 7000:7000

        # hadoop

  namenode:
    # image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    container_name: namenode
    restart: always
    build:
      context: docker-hadoop/namenode
    ports:
      - 9870:9870
      - 9000:8020
      - 50070:50070
      - 8020:8020
    volumes:
      - hadoop_namenode:/hadoop/dfs/name
    environment:
      - CLUSTER_NAME=test
      # - HADOOP_CLASSPATH=${JAVA_HOME}/lib/tools.jar
      - HADOOP_CLASSPATH=/usr/lib/jvm/java-8-openjdk-amd64/lib/tools.jar
    env_file:
      - ./docker-hadoop/hadoop.env

  datanode:
    # image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: datanode
    restart: always
    build:
      context: docker-hadoop/datanode
    volumes:
      - hadoop_datanode:/hadoop/dfs/data
    environment:
      SERVICE_PRECONDITION: "namenode:9870"
    env_file:
      - ./docker-hadoop/hadoop.env
  
  resourcemanager:
    # image: bde2020/hadoop-resourcemanager:2.0.0-hadoop3.2.1-java8
    container_name: resourcemanager
    restart: always
    build:
      context: docker-hadoop/resourcemanager
    ports:
      - 8032:8032
      - 8088:8088
    environment:
      SERVICE_PRECONDITION: "namenode:8020 namenode:9870 datanode:9864"
    env_file:
      - ./docker-hadoop/hadoop.env

  nodemanager1:
    # image: bde2020/hadoop-nodemanager:2.0.0-hadoop3.2.1-java8
    container_name: nodemanager
    restart: always
    build:
      context: docker-hadoop/nodemanager
    environment:
      SERVICE_PRECONDITION: "namenode:8020 namenode:9870 datanode:9864 resourcemanager:8088"
    env_file:
      - ./docker-hadoop/hadoop.env
  
  historyserver:
    # image: bde2020/hadoop-historyserver:2.0.0-hadoop3.2.1-java8
    container_name: historyserver
    restart: always
    build:
      context: docker-hadoop/historyserver
    environment:
      SERVICE_PRECONDITION: "namenode:8020 namenode:9870 datanode:9864 resourcemanager:8088"
    ports:
      - 8188:8188
    volumes:
      - hadoop_historyserver:/hadoop/yarn/timeline
    env_file:
      - ./docker-hadoop/hadoop.env
  
volumes:
  hadoop_namenode:
  hadoop_datanode:
  hadoop_historyserver:

# volumes:
#   zookeeper_data:
#     driver: local
#   kafka_data:
#     driver: local
