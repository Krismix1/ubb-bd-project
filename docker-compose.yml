version: "3"
services:
  # https://raw.githubusercontent.com/bitnami/containers/main/bitnami/spark/docker-compose.yml
  spark:
    image: bitnami/spark:3.3-debian-11
    container_name: spark
    environment:
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - KAFKA_HOST=kafka:29092
      - PYSPARK_SUBMIT_ARGS=--packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1 pyspark-shell
    ports:
      - '8080:8080'
      - '7077:7077'
  spark-worker:
    # image: docker.io/bitnami/spark:3.3
    # build: Dockerfile.spark
    container_name: spark-worker
    build:
      dockerfile: Dockerfile.spark
    ports:
      - '8091:8081'
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark:7077
      - SPARK_WORKER_MEMORY=4G
      - SPARK_WORKER_CORES=2
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - KAFKA_HOST=kafka:29092
      - PYSPARK_SUBMIT_ARGS=--packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1 pyspark-shell
    depends_on:
      - spark

  # https://github.com/bitnami/containers/blob/main/bitnami/kafka/docker-compose.yml
  zookeeper:
    image: docker.io/bitnami/zookeeper:3.8
    ports:
      - "2181:2181"
    # volumes:
    #   - "zookeeper_data:/bitnami"
    environment:
      - ALLOW_ANONYMOUS_LOGIN=yes

  kafka:
    image: docker.io/bitnami/kafka:3.3
    container_name: kafka
    ports:
      - "9092:9092"
    # volumes:
    #   - "kafka_data:/bitnami"
    environment:
      - KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      - KAFKA_LISTENERS=PLAINTEXT://kafka:29092,CONTROLLER://kafka:29093,PLAINTEXT_HOST://0.0.0.0:9092
    depends_on:
      - zookeeper

  kafka-ui:
    container_name: kafka-ui
    image: provectuslabs/kafka-ui:latest
    ports:
      - 8081:8080
    depends_on:
      - kafka
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:29092

  # cassandra:
  #   container_name: cassandra
  #   image: cassandra:4.1.0
  #   ports:
  #     - 7000:7000

        # hadoop

  namenode:
    image: uhopper/hadoop-namenode
    hostname: namenode
    container_name: namenode
    domainname: hadoop
    # net: hadoop
    ports:
      - 50070:50070
      - 8020:8020
    volumes:
      - hadoop_name:/hadoop/dfs/name
    environment:
      - CLUSTER_NAME=bd-project

  datanode1:
    image: uhopper/hadoop-datanode
    hostname: datanode1
    container_name: datanode1
    domainname: hadoop
    # net: hadoop
    expose:
      - 50020
      - 50075
    volumes:
      - hadoop_data:/hadoop/dfs/data
    environment:
      - CORE_CONF_fs_defaultFS=hdfs://namenode:8020
      - CLUSTER_NAME=bd-project

  resourcemanager:
    image: uhopper/hadoop-resourcemanager
    hostname: resourcemanager
    container_name: resourcemanager
    domainname: hadoop
    # net: hadoop
    environment:
      - CORE_CONF_fs_defaultFS=hdfs://namenode:8020
      - YARN_CONF_yarn_log___aggregation___enable=true

  nodemanager1:
    image: uhopper/hadoop-nodemanager
    hostname: nodemanager1
    container_name: nodemanager1
    domainname: hadoop
    # net: hadoop
    environment:
      - CORE_CONF_fs_defaultFS=hdfs://namenode:8020
      - YARN_CONF_yarn_resourcemanager_hostname=resourcemanager
      - YARN_CONF_yarn_log___aggregation___enable=true
      - YARN_CONF_yarn_nodemanager_remote___app___log___dir=/app-logs

volumes:
  hadoop_name:
    driver: local
  hadoop_data:
    driver: local

# volumes:
#   zookeeper_data:
#     driver: local
#   kafka_data:
#     driver: local
